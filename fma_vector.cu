#include <cuda.h>
#include <cuda_runtime_api.h> 
#include <omp.h>
#include <cstdio>
#include <string>
#include <random>
#include <iostream>
#include <iomanip>

#include "utils.hpp"

#define NUM_ITERATION   10

#ifndef DATA_T
#define DATA_T          float
#endif
#define STRINGIFY(s)    #s
#define MACRO_STR(m)   STRINGIFY(m)

__global__ void fma_vector_d(DATA_T * C, DATA_T * A, DATA_T * B, int N) {
    int i = threadIdx.x + blockDim.x * blockIdx.x;

    if (i < N)
        C[i] += A[i] * B[i];

    /*
    * single-precision FMA operation for round-to-nearest:
    *       C[i] = __fmaf_rn(A[i], B[i], C[i]);
    * 
    * double-precision FMA operation for round-to-nearest.
    *       C[i] = __fma_rn(A[i], B[i], C[i]);
    */

    /* PTX code:
        //
        // Generated by NVIDIA NVVM Compiler
        //
        // Compiler Build ID: CL-35059454
        // Cuda compilation tools, release 12.6, V12.6.85
        // Based on NVVM 7.0.1
        //

        .version 8.5
        .target sm_52
        .address_size 64

            // .globl	_Z12fma_vector_dPfS_S_i

        .visible .entry _Z12fma_vector_dPfS_S_i(
            .param .u64 _Z12fma_vector_dPfS_S_i_param_0,
            .param .u64 _Z12fma_vector_dPfS_S_i_param_1,
            .param .u64 _Z12fma_vector_dPfS_S_i_param_2,
            .param .u32 _Z12fma_vector_dPfS_S_i_param_3
        )
        {
            .reg .pred 	%p<2>;
            .reg .f32 	%f<5>;
            .reg .b32 	%r<6>;
            .reg .b64 	%rd<11>;


            ld.param.u64 	%rd1, [_Z12fma_vector_dPfS_S_i_param_0];
            ld.param.u64 	%rd2, [_Z12fma_vector_dPfS_S_i_param_1];
            ld.param.u64 	%rd3, [_Z12fma_vector_dPfS_S_i_param_2];
            ld.param.u32 	%r2, [_Z12fma_vector_dPfS_S_i_param_3];
            mov.u32 	%r3, %tid.x;
            mov.u32 	%r4, %ctaid.x;
            mov.u32 	%r5, %ntid.x;
            mad.lo.s32 	%r1, %r5, %r4, %r3;
            setp.ge.s32 	%p1, %r1, %r2;
            @%p1 bra 	$L__BB0_2;

            cvta.to.global.u64 	%rd4, %rd2;
            mul.wide.s32 	%rd5, %r1, 4;
            add.s64 	%rd6, %rd4, %rd5;
            cvta.to.global.u64 	%rd7, %rd3;
            add.s64 	%rd8, %rd7, %rd5;
            ld.global.f32 	%f1, [%rd8];
            ld.global.f32 	%f2, [%rd6];
            cvta.to.global.u64 	%rd9, %rd1;
            add.s64 	%rd10, %rd9, %rd5;
            ld.global.f32 	%f3, [%rd10];

            // It uses FMA instruction!!!
            fma.rn.f32 	%f4, %f2, %f1, %f3;
            
            st.global.f32 	[%rd10], %f4;

        $L__BB0_2:
            ret;

        }
    */
}

__host__ void fma_vector_h(DATA_T * C, DATA_T * A, DATA_T * B, int N) {
    #pragma omp parallel for
    for (int i = 0; i < N; i++) {
        C[i] += A[i] * B[i];
    }
}

// compile command: nvcc -g -O3 -Xcompiler -fopenmp fma_vector.cu
int main(int argc, const char * argv[]) {
    DATA_T * A_h, * B_h, * C_h;
    DATA_T * A_d, * B_d, * C_d;
    int N;

    bool is_data_type_valid = 
        std::is_same<DATA_T, float>::value || std::is_same<DATA_T, double>::value;

    if (argc > 1 && is_data_type_valid) {
        N = std::stoi(argv[1]);
    }
    else {
        perror("Usage: ./fma_vector <vector size>\n");
        exit(1);
    }

    int device;
    cudaDeviceProp props;
    cudaGetDevice(&device);
    cudaGetDeviceProperties(&props, device);
    std::string bytes_s = utils::formatBytes(N * sizeof(DATA_T));

    // Through the experiment, I found that the following two lines' performances are nearly the same.
    int num_threads_per_block = props.maxThreadsPerBlock;
    // int num_threads_per_block = std::gcd(props.maxThreadsPerBlock, props.maxThreadsPerMultiProcessor);
    int num_blocks = std::ceil((float)N / num_threads_per_block);

    printf("Fused Multiply-Add Vector Operation\n");
    printf("- data type: %s\n", MACRO_STR(DATA_T));
    printf("- vector size: %d (%s)\n", N, bytes_s.c_str());
    printf("- #blocks: %d\n", num_blocks);
    printf("- #threads per block: %d\n", num_threads_per_block);

    A_h = new DATA_T[N];
    B_h = new DATA_T[N];
    C_h = new DATA_T[N];

    cudaMalloc((void **)&A_d, sizeof(DATA_T) * N);
    cudaMalloc((void **)&B_d, sizeof(DATA_T) * N);
    cudaMalloc((void **)&C_d, sizeof(DATA_T) * N);

    utils::random_fill_d<DATA_T>(A_d, N);
    utils::random_fill_d<DATA_T>(B_d, N);
    utils::random_fill_d<DATA_T>(C_d, N);
    cudaMemcpyAsync(A_h, A_d, sizeof(DATA_T) * N, cudaMemcpyDeviceToHost);
    cudaMemcpyAsync(B_h, B_d, sizeof(DATA_T) * N, cudaMemcpyDeviceToHost);
    cudaMemcpyAsync(C_h, C_d, sizeof(DATA_T) * N, cudaMemcpyDeviceToHost);

    cudaDeviceSynchronize();

    fma_vector_h(C_h, A_h, B_h, N);
    fma_vector_d<<<num_blocks, num_threads_per_block>>>(C_d, A_d, B_d, N);
    cudaMemcpy(A_h, C_d, sizeof(DATA_T) * N, cudaMemcpyDeviceToHost);

    if (utils::is_equal_vector_h<DATA_T>(C_h, A_h, N)) {
        printf("- calculation: correct\n");
    }
    else {
        printf("- calculation: incorrect\n");
        exit(1);
    }

    double total_time = 0.0;

    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    for (int k = 0; k < NUM_ITERATION; k++) {
        cudaEventRecord(start);

        fma_vector_d<<<num_blocks, num_threads_per_block>>>(C_d, A_d, B_d, N);

        cudaEventRecord(stop);
        cudaEventSynchronize(stop);

        float tdiff;
        cudaEventElapsedTime(&tdiff, start, stop); 

        printf("- test %d: %.6f (ms)\n", k, tdiff);
        total_time += tdiff;
    }

    printf("Average time: %.6f (ms)\n", total_time / NUM_ITERATION);

    cudaEventDestroy(start);
    cudaEventDestroy(stop);

    delete[] A_h;
    delete[] B_h;
    delete[] C_h;
    cudaFree(A_d);
    cudaFree(B_d);
    cudaFree(C_d);

    return 0;
}